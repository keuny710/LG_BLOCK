{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f63c051d4f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import signal\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from module.simulator import Simulator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "torch.manual_seed(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper parameters ###\n",
    "clip_range = 0.2\n",
    "gamma = 1.0\n",
    "lam = 1.0\n",
    "learning_rate = 0.0005\n",
    "\n",
    "HORIZON = 24 * 7 * 14\n",
    "train_iter = 3\n",
    "\n",
    "save_interval = 100\n",
    "\n",
    "# True -> train\n",
    "# False -> inference\n",
    "is_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myEnv(gym.Env):\n",
    "    def __init__(self, is_train):\n",
    "        self.is_train = is_train\n",
    "        self.simulator = Simulator()\n",
    "\n",
    "        self.submission_ini = pd.read_csv(\"data/sample_submission.csv\")\n",
    "        self.submission_ini['time'] = pd.to_datetime(self.submission_ini['time'])\n",
    "        self.submission_ini[['Event_A', 'Event_B']] = 'STOP'\n",
    "        self.submission_ini[['MOL_A', 'MOL_B']] = 0\n",
    "        \n",
    "        over_prod, score = self.simulator.initialize_over_prod()\n",
    "        over_prod[over_prod > 0] = 0\n",
    "        shortage_ini = -over_prod\n",
    "        for i in range(4):\n",
    "            temp_arr = shortage_ini[:, i].copy()\n",
    "            temp_idx = np.where(temp_arr > 0)[0]\n",
    "            temp_values = temp_arr[temp_idx]\n",
    "            temp_values[1:] -= temp_values[:-1].copy()\n",
    "            shortage_ini[temp_idx, i] = temp_values\n",
    "        self.shortage_ini = np.append(shortage_ini, np.zeros((31, 4)), axis=0)\n",
    "        \n",
    "        self.best_mean_score = 0\n",
    "        self.best_score = 0\n",
    "        self.mean_score = []\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self.submission = self.submission_ini.copy()\n",
    "        self.shortage = self.shortage_ini.copy()\n",
    "        self.step_count = 0\n",
    "        \n",
    "        self.mask = {'A': np.zeros([5]), 'B': np.zeros([5])}\n",
    "        self.event_map = {0:'CHECK_1', 1:'CHECK_2', 2:'CHECK_3', 3:'CHECK_4', 4:'PROCESS'}\n",
    "        self.check_time = {'A': 28, 'B': 28}\n",
    "        self.process = {'A': 0, 'B': 0}\n",
    "        self.process_mode = {'A': 0, 'B': 0}\n",
    "        self.process_time = {'A': 0, 'B': 0}\n",
    "        \n",
    "        s = 0\n",
    "        state_ini = np.concatenate((np.array(list(self.process_time.values())), \n",
    "                                    self.shortage[s//24+3:(s//24+31)].reshape(-1)))\n",
    "        \n",
    "        return state_ini\n",
    "    \n",
    "    \n",
    "    def update_mask(self):\n",
    "        for line in ['A', 'B']:\n",
    "            self.mask[line][:] = 0\n",
    "            if self.process[line] == 0:\n",
    "                if self.check_time[line] == 28:\n",
    "                    self.mask[line][:4] = 1\n",
    "                if self.check_time[line] < 28:\n",
    "                    self.mask[line][self.process_mode[line]] = 1\n",
    "            if self.process[line] == 1:\n",
    "                self.mask[line][4] = 1\n",
    "                if self.process_time[line] > 98:\n",
    "                    self.mask[line][:4] = 1\n",
    "                    \n",
    "                    \n",
    "    def save_csv(self, submission, score):\n",
    "        # PRT 투입\n",
    "        for line in ['A', 'B']:\n",
    "            state = submission['Event_'+line].str[-1].replace('S', np.nan).replace('P', np.nan).fillna(method='ffill')\n",
    "            dates = (submission['time'] - np.timedelta64(23, 'D')).dt.date\n",
    "            mol_input = (submission.groupby([state, dates]).sum()['MOL_'+line])\n",
    "            for item in state.unique():\n",
    "                PRT_delta = mol_input.loc[item]\n",
    "                PRT_delta = PRT_delta.loc[(PRT_delta.index >= submission.iloc[0, 0]) & (PRT_delta.index <= submission.iloc[-1, 0])]\n",
    "                submission.loc[submission['time'].isin(PRT_delta.index), 'PRT_'+item] += (PRT_delta.values * 1.2).astype(int)\n",
    "        submission.to_csv(f\"save_score_{score:.2f}.csv\", index=False)\n",
    "        \n",
    "        \n",
    "    def step(self, action_A, action_B, n_epoch):\n",
    "        event_A = self.event_map[action_A]\n",
    "        event_B = self.event_map[action_B]\n",
    "        \n",
    "        self.submission['Event_A'].iloc[self.step_count] = event_A\n",
    "        self.submission['Event_B'].iloc[self.step_count] = event_B\n",
    "        \n",
    "        # update mask\n",
    "        for event, line in zip([event_A, event_B], ['A', 'B']):\n",
    "            if 'CHECK' in event:\n",
    "                if self.process[line] == 1:\n",
    "                    self.process[line] = 0\n",
    "                    self.check_time[line] = 28\n",
    "                self.check_time[line] -= 1\n",
    "                self.process_mode[line] = int(event[-1]) - 1\n",
    "                if self.check_time[line] == 0:\n",
    "                    self.process[line] = 1\n",
    "                    self.process_time[line] = 0\n",
    "            elif event == 'PROCESS':\n",
    "                self.process_time[line] += 1\n",
    "                if self.process_time[line] == 140:\n",
    "                    self.process[line] = 0\n",
    "                    self.check_time[line] = 28\n",
    "        \n",
    "        info = {'saved': False, 'score': 0}\n",
    "        self.step_count += 1\n",
    "        if self.step_count == self.submission.shape[0]:\n",
    "            done = True\n",
    "            self.submission, _, score = self.simulator.get_score(self.submission)\n",
    "            reward = score - self.best_mean_score\n",
    "            if reward > 0:\n",
    "                reward = 2\n",
    "            elif reward > -1:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = 0\n",
    "            \n",
    "            if (score > 62) and (score > self.best_score):\n",
    "                self.save_csv(self.submission, score)\n",
    "                print('result saved (score : %s)' % score)\n",
    "                self.best_score = score\n",
    "                info = {'saved': True, 'score': score}\n",
    "                \n",
    "            self.mean_score.append(score)\n",
    "            if (n_epoch+1) % 5 == 0:\n",
    "                mean_score = sum(self.mean_score)/5\n",
    "                if mean_score > self.best_mean_score:\n",
    "                    self.best_mean_score = mean_score\n",
    "                print('Epoch %s~%s mean score : %s / best mean score : %s' \n",
    "                      % (n_epoch-3, n_epoch+1, mean_score, self.best_mean_score))\n",
    "                self.mean_score = []\n",
    "            \n",
    "        else:\n",
    "            done = False\n",
    "            reward = 0\n",
    "            \n",
    "        s = self.step_count\n",
    "        state = np.concatenate((np.array(list(self.process_time.values())),\n",
    "                                self.shortage[s//24+3:(s//24+31)].reshape(-1)))\n",
    "            \n",
    "        return state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PPO, self).__init__()\n",
    "        self.buffer = []\n",
    "        \n",
    "        input_shape = 4 * 28 + 2 ## 향후 4주치 order (shortage) & Process time\n",
    "        hidden_size_1 = input_shape * 2\n",
    "        hidden_size_2 = input_shape * 2\n",
    "        hidden_size_3 = input_shape\n",
    "        output_shape = 5  # CHECK 1, 2, 3, 4 & PROCESS\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_shape, hidden_size_1)\n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.fc3 = nn.Linear(hidden_size_2, hidden_size_3)\n",
    "        \n",
    "        self.fc_pi_A = nn.Linear(hidden_size_3, output_shape)\n",
    "        self.fc_pi_B = nn.Linear(hidden_size_3, output_shape)\n",
    "        self.fc_v  = nn.Linear(hidden_size_3, 1)\n",
    "        \n",
    "        self.epoch = 1\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate/(self.epoch // 200 + 1))\n",
    "        \n",
    "        \n",
    "    def pi(self, x, env=None, update=False, softmax_dim=0):\n",
    "        if update==True:\n",
    "            env.update_mask()\n",
    "        x = self.fc1(x)\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        x_A = self.fc_pi_A(x)\n",
    "        x_B = self.fc_pi_B(x)\n",
    "        \n",
    "        if softmax_dim==0:\n",
    "            prob_A = F.softmax(x_A, dim=softmax_dim) * torch.tensor(env.mask['A'])\n",
    "            prob_B = F.softmax(x_B, dim=softmax_dim) * torch.tensor(env.mask['B'])\n",
    "        elif softmax_dim==1:\n",
    "            prob_A = F.softmax(x_A, dim=softmax_dim)\n",
    "            prob_B = F.softmax(x_B, dim=softmax_dim)\n",
    "            \n",
    "        return prob_A, prob_B\n",
    "    \n",
    "    \n",
    "    def v(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "      \n",
    "        \n",
    "    def store(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "        \n",
    "    def train_net(self):\n",
    "        states = torch.tensor([e[0] for e in self.buffer], dtype=torch.float)\n",
    "        actions_A = torch.tensor([[e[1]] for e in self.buffer])\n",
    "        actions_B = torch.tensor([[e[2]] for e in self.buffer])\n",
    "        rewards = torch.tensor([[e[3]] for e in self.buffer], dtype=torch.float)\n",
    "        next_states = torch.tensor([e[4] for e in self.buffer], dtype=torch.float)\n",
    "        prob_actions_A = torch.tensor([[e[5]] for e in self.buffer], dtype=torch.float)\n",
    "        prob_actions_B =torch.tensor([[e[6]] for e in self.buffer], dtype=torch.float)\n",
    "        dones = torch.tensor([[1-e[7]] for e in self.buffer])\n",
    "        self.buffer = []\n",
    "\n",
    "        for _ in range(train_iter):\n",
    "            td_target = rewards + gamma * self.v(next_states) * dones\n",
    "            delta = td_target - self.v(states)\n",
    "            delta = delta.detach().numpy()\n",
    "\n",
    "            advantages = []\n",
    "            advantage = 0.0\n",
    "            for delta_t in delta[::-1]:\n",
    "                advantage = gamma * lam * advantage + delta_t[0]\n",
    "                advantages.append([advantage])\n",
    "            advantages.reverse()\n",
    "            advs = torch.tensor(advantages, dtype=torch.float)\n",
    "\n",
    "            new_probs_A, new_probs_B = self.pi(states, softmax_dim=1)\n",
    "            \n",
    "            new_prob_actions_A = new_probs_A.gather(1, actions_A)\n",
    "            new_prob_actions_B = new_probs_B.gather(1, actions_B)\n",
    "            \n",
    "            ratio_A = torch.exp(torch.log(new_prob_actions_A) - torch.log(prob_actions_A))\n",
    "            ratio_B = torch.exp(torch.log(new_prob_actions_B) - torch.log(prob_actions_B))\n",
    "            \n",
    "            surr1_A = ratio_A * advs\n",
    "            surr2_A = torch.clamp(ratio_A, 1-clip_range, 1+clip_range) * advs\n",
    "            \n",
    "            surr1_B = ratio_B * advs\n",
    "            surr2_B = torch.clamp(ratio_B, 1-clip_range, 1+clip_range) * advs\n",
    "\n",
    "            pi_loss_A = -torch.mean(torch.min(surr1_A, surr2_A))\n",
    "            pi_loss_B = -torch.mean(torch.min(surr1_B, surr2_B))\n",
    "            vf_loss = torch.mean(torch.pow(self.v(states) - td_target.detach(), 2))\n",
    "\n",
    "            loss = pi_loss_A + pi_loss_B + vf_loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GracefulKiller:\n",
    "    def __init__(self):\n",
    "        self.kill_now = False\n",
    "        signal.signal(signal.SIGINT, self.exit_gracefully)\n",
    "        signal.signal(signal.SIGTERM, self.exit_gracefully)\n",
    "\n",
    "    def exit_gracefully(self, signum, frame):\n",
    "        self.kill_now = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = myEnv(is_train)\n",
    "    killer = GracefulKiller()\n",
    "\n",
    "    model = PPO()\n",
    "    \n",
    "    if os.path.exists(\"save.pt\"):\n",
    "        print(\"model loaded!\")\n",
    "        checkpoint = torch.load(\"save.pt\")\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "    if not is_train:\n",
    "        model.eval()\n",
    "\n",
    "    for i in tqdm(itertools.count()):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            for t in range(HORIZON):\n",
    "                \n",
    "                prob_A, prob_B = model.pi(torch.from_numpy(state).float(), env=env, update=True)\n",
    "                m_A = Categorical(prob_A)\n",
    "                m_B = Categorical(prob_B)\n",
    "                \n",
    "                action_A = m_A.sample().item()\n",
    "                action_B = m_B.sample().item()\n",
    "                prob_action_A = prob_A[action_A].item()\n",
    "                prob_action_B = prob_B[action_B].item()\n",
    "                \n",
    "                next_state, reward, done, info = env.step(action_A, action_B, i)\n",
    "                if info['saved']:\n",
    "                    torch.save({\"model\": model.state_dict()}, f\"save_score_{info['score']:.2f}.pt\")\n",
    "                model.store((state, action_A, action_B, reward,\n",
    "                             next_state, prob_action_A, prob_action_B, done))\n",
    "                \n",
    "                state = next_state\n",
    "                if done:\n",
    "                    break\n",
    "            model.train_net()\n",
    "        model.epoch += 1\n",
    "        \n",
    "                               \n",
    "        if i == 999:\n",
    "            killer.kill_now = True\n",
    "                               \n",
    "                               \n",
    "        if (i+1)%save_interval==0:\n",
    "            torch.save({\"model\": model.state_dict()}, f\"save_epoch_{i+1}.pt\")\n",
    "            if killer.kill_now:\n",
    "                if input('Terminate training (y/[n])? ') == 'y':\n",
    "                    break\n",
    "                killer.kill_now = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54b96460ec34d73b0d9e1ac82140ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeok9855/.conda/envs/RL/lib/python3.8/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/hyeok9855/.conda/envs/RL/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1~5 mean score : 55.759431326328695 / best mean score : 55.759431326328695\n",
      "Epoch 6~10 mean score : 56.52649619072694 / best mean score : 56.52649619072694\n",
      "Epoch 11~15 mean score : 55.145271871715714 / best mean score : 56.52649619072694\n",
      "Epoch 16~20 mean score : 55.77624054440393 / best mean score : 56.52649619072694\n",
      "Epoch 21~25 mean score : 55.16228323517404 / best mean score : 56.52649619072694\n",
      "Epoch 26~30 mean score : 56.07618626007386 / best mean score : 56.52649619072694\n",
      "Epoch 31~35 mean score : 56.83494233480375 / best mean score : 56.83494233480375\n",
      "Epoch 36~40 mean score : 57.73759667572225 / best mean score : 57.73759667572225\n",
      "Epoch 41~45 mean score : 57.2215808936362 / best mean score : 57.73759667572225\n",
      "Epoch 46~50 mean score : 57.250647679337206 / best mean score : 57.73759667572225\n",
      "Epoch 51~55 mean score : 58.42926690348603 / best mean score : 58.42926690348603\n",
      "Epoch 56~60 mean score : 58.576292278875826 / best mean score : 58.576292278875826\n",
      "Epoch 61~65 mean score : 58.85442374280471 / best mean score : 58.85442374280471\n",
      "Epoch 66~70 mean score : 58.78635580106559 / best mean score : 58.85442374280471\n",
      "Epoch 71~75 mean score : 59.56947008724509 / best mean score : 59.56947008724509\n",
      "Epoch 76~80 mean score : 59.57130567791974 / best mean score : 59.57130567791974\n",
      "Epoch 81~85 mean score : 59.62628461394072 / best mean score : 59.62628461394072\n",
      "Epoch 86~90 mean score : 60.791914799100354 / best mean score : 60.791914799100354\n",
      "Epoch 91~95 mean score : 59.77066766039453 / best mean score : 60.791914799100354\n",
      "Epoch 96~100 mean score : 60.426189869812845 / best mean score : 60.791914799100354\n",
      "Epoch 101~105 mean score : 59.947001289982474 / best mean score : 60.791914799100354\n",
      "Epoch 106~110 mean score : 60.34572974022475 / best mean score : 60.791914799100354\n",
      "Epoch 111~115 mean score : 60.40411344349745 / best mean score : 60.791914799100354\n",
      "Epoch 116~120 mean score : 60.110293285916214 / best mean score : 60.791914799100354\n",
      "Epoch 121~125 mean score : 60.850413952578165 / best mean score : 60.850413952578165\n",
      "result saved (score : 62.12960652616232)\n",
      "result saved (score : 62.137797100719084)\n",
      "Epoch 126~130 mean score : 61.69673277148386 / best mean score : 61.69673277148386\n",
      "Epoch 131~135 mean score : 60.70753526100564 / best mean score : 61.69673277148386\n",
      "Epoch 136~140 mean score : 61.03009059984031 / best mean score : 61.69673277148386\n",
      "Epoch 141~145 mean score : 60.256080044656315 / best mean score : 61.69673277148386\n",
      "Epoch 146~150 mean score : 60.084306360237214 / best mean score : 61.69673277148386\n",
      "Epoch 151~155 mean score : 61.6784323471936 / best mean score : 61.69673277148386\n",
      "Epoch 156~160 mean score : 61.12975583111091 / best mean score : 61.69673277148386\n",
      "Epoch 161~165 mean score : 60.595116560775864 / best mean score : 61.69673277148386\n",
      "Epoch 166~170 mean score : 60.858985777013984 / best mean score : 61.69673277148386\n",
      "Epoch 171~175 mean score : 61.16176029919975 / best mean score : 61.69673277148386\n",
      "Epoch 176~180 mean score : 60.09240827346031 / best mean score : 61.69673277148386\n",
      "Epoch 216~220 mean score : 61.05951946540226 / best mean score : 61.69673277148386\n",
      "Epoch 221~225 mean score : 61.40605704985096 / best mean score : 61.69673277148386\n",
      "Epoch 226~230 mean score : 61.46668751610942 / best mean score : 61.69673277148386\n",
      "Epoch 231~235 mean score : 61.66322493159161 / best mean score : 61.69673277148386\n",
      "Epoch 236~240 mean score : 61.276712268166435 / best mean score : 61.69673277148386\n",
      "Epoch 241~245 mean score : 61.309362434076185 / best mean score : 61.69673277148386\n",
      "Epoch 246~250 mean score : 61.184515602213516 / best mean score : 61.69673277148386\n",
      "Epoch 251~255 mean score : 61.56332265567422 / best mean score : 61.69673277148386\n",
      "Epoch 256~260 mean score : 61.37361468202194 / best mean score : 61.69673277148386\n",
      "Epoch 261~265 mean score : 60.79788951618131 / best mean score : 61.69673277148386\n",
      "Epoch 266~270 mean score : 61.69720182250346 / best mean score : 61.69720182250346\n",
      "Epoch 271~275 mean score : 61.153096372657785 / best mean score : 61.69720182250346\n",
      "Epoch 276~280 mean score : 60.50466209310177 / best mean score : 61.69720182250346\n",
      "Epoch 281~285 mean score : 61.20583315387042 / best mean score : 61.69720182250346\n",
      "Epoch 286~290 mean score : 61.44445957292025 / best mean score : 61.69720182250346\n",
      "Epoch 291~295 mean score : 61.91779564453502 / best mean score : 61.91779564453502\n",
      "Epoch 296~300 mean score : 61.27699183093027 / best mean score : 61.91779564453502\n",
      "Epoch 301~305 mean score : 61.58489752795858 / best mean score : 61.91779564453502\n",
      "Epoch 306~310 mean score : 61.14327499483115 / best mean score : 61.91779564453502\n",
      "Epoch 311~315 mean score : 61.3513831137332 / best mean score : 61.91779564453502\n",
      "Epoch 316~320 mean score : 61.65841030781704 / best mean score : 61.91779564453502\n",
      "Epoch 321~325 mean score : 61.398258661914305 / best mean score : 61.91779564453502\n",
      "Epoch 326~330 mean score : 61.14492171167372 / best mean score : 61.91779564453502\n",
      "Epoch 331~335 mean score : 61.34751408796642 / best mean score : 61.91779564453502\n",
      "Epoch 336~340 mean score : 61.49356707647701 / best mean score : 61.91779564453502\n",
      "Epoch 341~345 mean score : 61.159188874753724 / best mean score : 61.91779564453502\n",
      "Epoch 346~350 mean score : 61.16665086573829 / best mean score : 61.91779564453502\n",
      "Epoch 351~355 mean score : 60.7999623972722 / best mean score : 61.91779564453502\n",
      "Epoch 356~360 mean score : 59.34630385768965 / best mean score : 61.91779564453502\n",
      "Epoch 361~365 mean score : 60.51352429415779 / best mean score : 61.91779564453502\n",
      "Epoch 366~370 mean score : 58.75249313151154 / best mean score : 61.91779564453502\n",
      "Epoch 371~375 mean score : 58.369601573907644 / best mean score : 61.91779564453502\n",
      "Epoch 376~380 mean score : 55.13551666731693 / best mean score : 61.91779564453502\n",
      "Epoch 381~385 mean score : 60.11430823730147 / best mean score : 61.91779564453502\n",
      "Epoch 386~390 mean score : 58.860856328394696 / best mean score : 61.91779564453502\n",
      "Epoch 391~395 mean score : 59.30796922843442 / best mean score : 61.91779564453502\n",
      "Epoch 396~400 mean score : 57.673891264831035 / best mean score : 61.91779564453502\n",
      "Epoch 401~405 mean score : 59.28215298964726 / best mean score : 61.91779564453502\n",
      "Epoch 406~410 mean score : 56.43565107249185 / best mean score : 61.91779564453502\n",
      "Epoch 411~415 mean score : 59.537681158975055 / best mean score : 61.91779564453502\n",
      "Epoch 416~420 mean score : 59.53976104449564 / best mean score : 61.91779564453502\n",
      "Epoch 421~425 mean score : 60.018848797403926 / best mean score : 61.91779564453502\n",
      "Epoch 426~430 mean score : 59.30713078591238 / best mean score : 61.91779564453502\n",
      "Epoch 431~435 mean score : 59.458926669458194 / best mean score : 61.91779564453502\n",
      "Epoch 436~440 mean score : 58.3027100077018 / best mean score : 61.91779564453502\n",
      "Epoch 441~445 mean score : 60.04297027141858 / best mean score : 61.91779564453502\n",
      "Epoch 446~450 mean score : 60.027777663426704 / best mean score : 61.91779564453502\n",
      "Epoch 451~455 mean score : 57.55030449300371 / best mean score : 61.91779564453502\n",
      "Epoch 456~460 mean score : 59.20161962075929 / best mean score : 61.91779564453502\n",
      "Epoch 461~465 mean score : 58.47475121218107 / best mean score : 61.91779564453502\n",
      "result saved (score : 62.30060462359947)\n",
      "Epoch 466~470 mean score : 60.204386001831594 / best mean score : 61.91779564453502\n",
      "Epoch 471~475 mean score : 60.468326491213894 / best mean score : 61.91779564453502\n",
      "Epoch 476~480 mean score : 60.77231431579471 / best mean score : 61.91779564453502\n",
      "result saved (score : 62.48260520545866)\n",
      "Epoch 481~485 mean score : 60.47963133351745 / best mean score : 61.91779564453502\n",
      "Epoch 486~490 mean score : 60.61233510789126 / best mean score : 61.91779564453502\n",
      "Epoch 491~495 mean score : 60.19146301338552 / best mean score : 61.91779564453502\n",
      "Epoch 496~500 mean score : 60.66198625349953 / best mean score : 61.91779564453502\n",
      "Epoch 501~505 mean score : 61.02952102911047 / best mean score : 61.91779564453502\n",
      "Epoch 506~510 mean score : 60.78540246131972 / best mean score : 61.91779564453502\n",
      "Epoch 511~515 mean score : 60.73051900673501 / best mean score : 61.91779564453502\n",
      "Epoch 516~520 mean score : 59.89787357188741 / best mean score : 61.91779564453502\n",
      "Epoch 521~525 mean score : 61.321119676518244 / best mean score : 61.91779564453502\n",
      "Epoch 526~530 mean score : 60.447624346291626 / best mean score : 61.91779564453502\n",
      "Epoch 531~535 mean score : 60.583305249052025 / best mean score : 61.91779564453502\n",
      "Epoch 536~540 mean score : 60.265922312887255 / best mean score : 61.91779564453502\n",
      "Epoch 541~545 mean score : 59.51674092488578 / best mean score : 61.91779564453502\n",
      "Epoch 546~550 mean score : 60.436918935707624 / best mean score : 61.91779564453502\n",
      "Epoch 551~555 mean score : 61.211705753739615 / best mean score : 61.91779564453502\n",
      "Epoch 556~560 mean score : 60.585606327089046 / best mean score : 61.91779564453502\n",
      "Epoch 561~565 mean score : 59.196025170479516 / best mean score : 61.91779564453502\n",
      "Epoch 566~570 mean score : 58.851202872553486 / best mean score : 61.91779564453502\n",
      "Epoch 571~575 mean score : 60.146252061775385 / best mean score : 61.91779564453502\n",
      "Epoch 576~580 mean score : 59.975241860192206 / best mean score : 61.91779564453502\n",
      "Epoch 581~585 mean score : 60.85091519939736 / best mean score : 61.91779564453502\n",
      "Epoch 586~590 mean score : 60.86125140280601 / best mean score : 61.91779564453502\n",
      "Epoch 591~595 mean score : 60.235079597048674 / best mean score : 61.91779564453502\n",
      "Epoch 596~600 mean score : 60.99986120169592 / best mean score : 61.91779564453502\n",
      "Epoch 601~605 mean score : 60.77089346108839 / best mean score : 61.91779564453502\n",
      "Epoch 606~610 mean score : 59.77678123722192 / best mean score : 61.91779564453502\n",
      "Epoch 611~615 mean score : 59.75471513322394 / best mean score : 61.91779564453502\n",
      "Epoch 616~620 mean score : 60.426911817609565 / best mean score : 61.91779564453502\n",
      "result saved (score : 62.745424003013134)\n",
      "Epoch 621~625 mean score : 60.81577243959678 / best mean score : 61.91779564453502\n",
      "Epoch 626~630 mean score : 61.17987959139598 / best mean score : 61.91779564453502\n",
      "Epoch 631~635 mean score : 61.25336939180967 / best mean score : 61.91779564453502\n",
      "Epoch 636~640 mean score : 61.3559525824687 / best mean score : 61.91779564453502\n",
      "Epoch 641~645 mean score : 59.92739896340585 / best mean score : 61.91779564453502\n",
      "Epoch 646~650 mean score : 60.971194098583666 / best mean score : 61.91779564453502\n",
      "Epoch 651~655 mean score : 60.593402195888714 / best mean score : 61.91779564453502\n",
      "Epoch 656~660 mean score : 60.243532899161096 / best mean score : 61.91779564453502\n",
      "Epoch 661~665 mean score : 61.26772540055047 / best mean score : 61.91779564453502\n",
      "Epoch 666~670 mean score : 60.948279475515676 / best mean score : 61.91779564453502\n",
      "Epoch 671~675 mean score : 60.41907054290167 / best mean score : 61.91779564453502\n",
      "Epoch 676~680 mean score : 60.88095000956965 / best mean score : 61.91779564453502\n",
      "Epoch 681~685 mean score : 60.77666351364927 / best mean score : 61.91779564453502\n",
      "Epoch 686~690 mean score : 60.51997641842006 / best mean score : 61.91779564453502\n",
      "Epoch 691~695 mean score : 60.92161717535313 / best mean score : 61.91779564453502\n",
      "Epoch 696~700 mean score : 60.93489997029261 / best mean score : 61.91779564453502\n",
      "Epoch 701~705 mean score : 61.44926086370149 / best mean score : 61.91779564453502\n",
      "Epoch 706~710 mean score : 61.04294004177467 / best mean score : 61.91779564453502\n",
      "Epoch 711~715 mean score : 61.47513885206614 / best mean score : 61.91779564453502\n",
      "Epoch 716~720 mean score : 61.2775762707126 / best mean score : 61.91779564453502\n",
      "Epoch 721~725 mean score : 61.36254375080451 / best mean score : 61.91779564453502\n",
      "Epoch 726~730 mean score : 61.60468067941739 / best mean score : 61.91779564453502\n",
      "Epoch 731~735 mean score : 60.37381424682566 / best mean score : 61.91779564453502\n",
      "Epoch 736~740 mean score : 61.63455500213051 / best mean score : 61.91779564453502\n",
      "Epoch 741~745 mean score : 61.562349162832405 / best mean score : 61.91779564453502\n",
      "Epoch 746~750 mean score : 60.91525518704132 / best mean score : 61.91779564453502\n",
      "Epoch 751~755 mean score : 60.58947572151002 / best mean score : 61.91779564453502\n",
      "Epoch 756~760 mean score : 61.528860554400616 / best mean score : 61.91779564453502\n",
      "Epoch 761~765 mean score : 61.151719940781845 / best mean score : 61.91779564453502\n",
      "Epoch 766~770 mean score : 61.464810267510835 / best mean score : 61.91779564453502\n",
      "Epoch 771~775 mean score : 61.61207612831993 / best mean score : 61.91779564453502\n",
      "Epoch 776~780 mean score : 61.305252615678306 / best mean score : 61.91779564453502\n",
      "Epoch 781~785 mean score : 61.01101747635928 / best mean score : 61.91779564453502\n",
      "Epoch 786~790 mean score : 60.07989811626923 / best mean score : 61.91779564453502\n",
      "Epoch 791~795 mean score : 61.31345388120671 / best mean score : 61.91779564453502\n",
      "Epoch 796~800 mean score : 60.488856720396996 / best mean score : 61.91779564453502\n",
      "Epoch 801~805 mean score : 61.71364822340936 / best mean score : 61.91779564453502\n",
      "Epoch 806~810 mean score : 61.27530640539734 / best mean score : 61.91779564453502\n",
      "Epoch 811~815 mean score : 61.79179934889525 / best mean score : 61.91779564453502\n",
      "Epoch 816~820 mean score : 61.980153440019805 / best mean score : 61.980153440019805\n",
      "Epoch 821~825 mean score : 61.36737637719223 / best mean score : 61.980153440019805\n",
      "Epoch 826~830 mean score : 62.30631329523701 / best mean score : 62.30631329523701\n",
      "Epoch 831~835 mean score : 61.06775231230663 / best mean score : 62.30631329523701\n",
      "Epoch 836~840 mean score : 61.37400047863603 / best mean score : 62.30631329523701\n",
      "Epoch 841~845 mean score : 62.05739878215087 / best mean score : 62.30631329523701\n",
      "result saved (score : 62.77177970577094)\n",
      "Epoch 846~850 mean score : 61.89515659047711 / best mean score : 62.30631329523701\n",
      "Epoch 851~855 mean score : 61.44941379374965 / best mean score : 62.30631329523701\n",
      "Epoch 856~860 mean score : 61.55883834605754 / best mean score : 62.30631329523701\n",
      "Epoch 861~865 mean score : 62.143953502875355 / best mean score : 62.30631329523701\n",
      "Epoch 866~870 mean score : 61.303605161527365 / best mean score : 62.30631329523701\n",
      "Epoch 871~875 mean score : 61.46979318192501 / best mean score : 62.30631329523701\n",
      "Epoch 876~880 mean score : 61.83151268339394 / best mean score : 62.30631329523701\n",
      "Epoch 881~885 mean score : 61.65179370234184 / best mean score : 62.30631329523701\n",
      "Epoch 886~890 mean score : 61.95883920625065 / best mean score : 62.30631329523701\n",
      "Epoch 891~895 mean score : 62.372123844461115 / best mean score : 62.372123844461115\n",
      "Epoch 896~900 mean score : 62.023680256386704 / best mean score : 62.372123844461115\n",
      "Epoch 901~905 mean score : 61.84586930655839 / best mean score : 62.372123844461115\n",
      "Epoch 906~910 mean score : 61.23687445143488 / best mean score : 62.372123844461115\n",
      "Epoch 911~915 mean score : 61.41163196145843 / best mean score : 62.372123844461115\n",
      "Epoch 916~920 mean score : 61.67863885498465 / best mean score : 62.372123844461115\n",
      "Epoch 921~925 mean score : 62.301523309851085 / best mean score : 62.372123844461115\n",
      "Epoch 926~930 mean score : 61.63712636513416 / best mean score : 62.372123844461115\n",
      "Epoch 931~935 mean score : 61.77964998127544 / best mean score : 62.372123844461115\n",
      "Epoch 936~940 mean score : 61.105695615134856 / best mean score : 62.372123844461115\n",
      "Epoch 941~945 mean score : 61.21570073635603 / best mean score : 62.372123844461115\n",
      "Epoch 946~950 mean score : 61.829195814668935 / best mean score : 62.372123844461115\n",
      "Epoch 951~955 mean score : 61.54905954779033 / best mean score : 62.372123844461115\n",
      "Epoch 956~960 mean score : 61.31934970629013 / best mean score : 62.372123844461115\n",
      "Epoch 961~965 mean score : 61.53736141290407 / best mean score : 62.372123844461115\n",
      "Epoch 966~970 mean score : 61.21732889760415 / best mean score : 62.372123844461115\n",
      "Epoch 971~975 mean score : 61.727311530919486 / best mean score : 62.372123844461115\n",
      "Epoch 976~980 mean score : 61.853112931375335 / best mean score : 62.372123844461115\n",
      "Epoch 981~985 mean score : 61.77731228358847 / best mean score : 62.372123844461115\n",
      "Epoch 986~990 mean score : 60.959144144711516 / best mean score : 62.372123844461115\n",
      "Epoch 991~995 mean score : 62.13887707318063 / best mean score : 62.372123844461115\n",
      "Epoch 996~1000 mean score : 61.58271257599269 / best mean score : 62.372123844461115\n",
      "Terminate training (y/[n])? y\n",
      "\n",
      "CPU times: user 2h 6min 32s, sys: 58min 45s, total: 3h 5min 18s\n",
      "Wall time: 47min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    is_train = False\n",
    "    env = myEnv(is_train)\n",
    "    killer = GracefulKiller()\n",
    "\n",
    "    model = PPO()\n",
    "    \n",
    "    if os.path.exists(\"save.pt\"):\n",
    "        print(\"model loaded!\")\n",
    "        checkpoint = torch.load(\"save.pt\")\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "    if not is_train:\n",
    "        model.eval()\n",
    "    \n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    for t in range(HORIZON):\n",
    "        prob_A, prob_B = model.pi(torch.from_numpy(state).float(), env=env, update=True)\n",
    "        action_A = np.argmax(prob_A.detach().numpy())\n",
    "        action_B = np.argmax(prob_B.detach().numpy())\n",
    "\n",
    "        next_state, reward, done, info = env.step(action_A, action_B, 0)\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    submission, score = env.submission, env.best_score\n",
    "    env.save_csv(submission, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kn]",
   "language": "python",
   "name": "conda-env-kn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
